FROM python:slim AS model-builder

RUN pip install huggingface_hub
RUN python -c \
    "from huggingface_hub import snapshot_download, hf_hub_download; \
    snapshot_download('winstxnhdw/Llama-3.2-1B-Instruct-ct2-int8');


FROM python:3.12-slim AS python-builder

WORKDIR /home/user

ENV UV_COMPILE_BYTECODE=1
ENV UV_NO_CACHE=1
ENV UV_LINK_MODE=copy

COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/
COPY pyproject.toml uv.lock ./

RUN uv sync --frozen --no-dev --no-editable --no-install-project

COPY . .

RUN uv sync --frozen --no-dev --no-editable


FROM python:3.12-slim

ENV HOME=/home/user
ENV PATH=$HOME/.venv/bin:$PATH
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV HF_HUB_OFFLINE=1

RUN useradd -m -u 1000 user

USER user

WORKDIR $HOME/app

COPY --chown=user --from=model-builder  /root/.cache/huggingface $HOME/.cache/huggingface
COPY --chown=user --from=python-builder $HOME/.venv .venv

CMD ["llm-api"]
